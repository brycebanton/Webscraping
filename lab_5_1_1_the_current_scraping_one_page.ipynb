{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study - The Current\n",
    "\n",
    "* The Current is an alternative radio station\n",
    "* We will pull information about the play list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0 - Inspect the following page\n",
    "\n",
    "* Song title\n",
    "* Artist\n",
    "* Play time\n",
    "* Day, date, period (am/pm)\n",
    "\n",
    "http://www.thecurrent.org/playlist/2014-01-01/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: composable in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (18.6.0)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (0.11.1)\n",
      "Requirement already satisfied: composablesoup in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.1.1)\n",
      "Requirement already satisfied: composable<0.3.0,>=0.2.0 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.3 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (4.9.3)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (18.6.0)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable<0.3.0,>=0.2.0->composablesoup) (0.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.9.3->composablesoup) (1.9.5)\n",
      "Requirement already up-to-date: composable in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (0.11.1)\n",
      "Requirement already satisfied, skipping upgrade: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (18.6.0)\n",
      "Requirement already up-to-date: composablesoup in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.1.1)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4<5.0.0,>=4.9.3 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (4.9.3)\n",
      "Requirement already satisfied, skipping upgrade: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (18.6.0)\n",
      "Requirement already satisfied, skipping upgrade: composable<0.3.0,>=0.2.0 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: soupsieve>1.2; python_version >= \"3.0\" in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.9.3->composablesoup) (1.9.5)\n",
      "Requirement already satisfied, skipping upgrade: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable<0.3.0,>=0.2.0->composablesoup) (0.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install composable\n",
    "!pip install composablesoup\n",
    "!pip install composable --upgrade\n",
    "!pip install composablesoup --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composablesoup import find, find_all, get_text, has_attr\n",
    "from composable.sequence import slice, head\n",
    "from composable.strict import map, filter\n",
    "from composable.string import replace,split\n",
    "from composable import from_toolz as tlz\n",
    "from composable import pipeable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "s = requests.Session()\n",
    "r = s.get('https://www.thecurrent.org/playlist/2014-01-01/01')\n",
    "the_current = BeautifulSoup(r.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"collapsedName js-mprnav-button\">\n",
       "<b>Stations</b>\n",
       "</span>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_current.find('span')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Pull off the period of the day (am/pm)\n",
    "\n",
    "Pull out the \"am\"/\"pm\"\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Search the soup\n",
    "    1. There should be one item returned\n",
    "4. Use soup\\string methods to pull out the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip = pipeable(lambda s: s.strip() )\n",
    "(the_current\n",
    " >> find(\"span\", attrs = {'class' : 'hour-header'})\n",
    " >> get_text\n",
    " >> strip\n",
    " >> split(\" \")\n",
    " >> tlz.get(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_period = pipeable(lambda soup: soup\n",
    "                        >> find(\"span\", attrs = {'class' : 'hour-header'})\n",
    "                         >> get_text\n",
    "                         >> strip\n",
    "                         >> split(\" \")\n",
    "                         >> tlz.get(1)\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_current >> get_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Pull off DJ\n",
    "\n",
    "Use a similar process to pull off the DJ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DJ: Jade'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (the_current\n",
    ">> find('h5', attrs ={'class':'currentDj'})\n",
    ">> get_text\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DJ: Jade'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_DJ = pipeable(lambda soup: soup\n",
    " >> find('h5', attrs ={'class':'currentDj'})\n",
    " >> get_text\n",
    "\n",
    ")\n",
    "the_current>>get_DJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Pull out the day of the week\n",
    "\n",
    "* Pull out the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wednesday, Jan 01, 2014'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (the_current\n",
    ">> find('a', attrs ={'class':'start-picker'})\n",
    ">> get_text\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wednesday, Jan 01, 2014'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_day = pipeable(lambda soup: soup\n",
    " >> find('a', attrs ={'class':'start-picker'})\n",
    " >> get_text\n",
    "\n",
    ")\n",
    "the_current>>get_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title of each song\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Use `find_all` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Write a function to pull out the title\n",
    "6. Write a single pipe to convert the original soup into a list of titles. \n",
    "7. Verify you have the right number of titles.\n",
    "8. Package the pipe in a function named `get_title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Holy Roller',\n",
       " 'Kingdom of Rust',\n",
       " 'Black Dog',\n",
       " 'Turn It Around',\n",
       " 'Flavor of the Month',\n",
       " 'Potential Wife',\n",
       " '24 Hours',\n",
       " \"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       " 'Marigold',\n",
       " 'High Road',\n",
       " 'The Vampyre Of Time and Memory',\n",
       " 'Valerie Plame',\n",
       " 'Morning Song',\n",
       " '(You Will) Set The World On Fire',\n",
       " 'Sixteen Saltines',\n",
       " 'Wave of Mutilation']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(the_current \n",
    " >> find_all('h5', attrs ={'class':'title'})\n",
    " >> map(get_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Holy Roller',\n",
       " 'Kingdom of Rust',\n",
       " 'Black Dog',\n",
       " 'Turn It Around',\n",
       " 'Flavor of the Month',\n",
       " 'Potential Wife',\n",
       " '24 Hours',\n",
       " \"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       " 'Marigold',\n",
       " 'High Road',\n",
       " 'The Vampyre Of Time and Memory',\n",
       " 'Valerie Plame',\n",
       " 'Morning Song',\n",
       " '(You Will) Set The World On Fire',\n",
       " 'Sixteen Saltines',\n",
       " 'Wave of Mutilation']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_title = pipeable(lambda soup: soup\n",
    " >> find_all('h5', attrs ={'class':'title'})\n",
    " >> map(get_text)\n",
    ")\n",
    "the_current>>get_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull off the name of the artist\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Use `find_all` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Write a function to pull out the artist\n",
    "6. Write a single pipe to convert the original soup into a list of artists. \n",
    "7. Verify you have the right number of artists.\n",
    "8. Package the pipe in a function named `get_artist`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thao and The Get Down Stay Down',\n",
       " 'Doves',\n",
       " 'Frankie Lee',\n",
       " 'Lucius',\n",
       " 'The Posies',\n",
       " 'Strange Names',\n",
       " 'Sky Ferreira',\n",
       " 'Billie Joe and Norah',\n",
       " 'J. Roddy Walston and The Business',\n",
       " 'Cults',\n",
       " 'Queens of the Stone Age',\n",
       " 'The Decemberists',\n",
       " 'The Avett Brothers',\n",
       " 'David Bowie',\n",
       " 'Jack White',\n",
       " 'Pixies']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(the_current\n",
    ">> find_all('h5', attrs ={'class':'artist'})\n",
    " >> map(get_text)\n",
    "\n",
    ")\n",
    "the_current>>get_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thao and The Get Down Stay Down',\n",
       " 'Doves',\n",
       " 'Frankie Lee',\n",
       " 'Lucius',\n",
       " 'The Posies',\n",
       " 'Strange Names',\n",
       " 'Sky Ferreira',\n",
       " 'Billie Joe and Norah',\n",
       " 'J. Roddy Walston and The Business',\n",
       " 'Cults',\n",
       " 'Queens of the Stone Age',\n",
       " 'The Decemberists',\n",
       " 'The Avett Brothers',\n",
       " 'David Bowie',\n",
       " 'Jack White',\n",
       " 'Pixies']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_artist = pipeable(lambda soup: soup\n",
    " >> find_all('h5', attrs ={'class':'artist'})\n",
    " >> map(get_text)\n",
    "\n",
    ")\n",
    "the_current>>get_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
