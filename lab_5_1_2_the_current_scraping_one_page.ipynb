{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study - The Current - Part 2\n",
    "\n",
    "* The Current is an alternative radio station\n",
    "* We will pull information about the play list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0 - Insert current progress\n",
    "\n",
    "Copy over all the relevant code from part 1 of the lab.\n",
    "\n",
    "http://www.thecurrent.org/playlist/2014-01-01/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: composable in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.5)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (18.6.0)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (0.11.1)\n",
      "Requirement already satisfied: composablesoup in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.3 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (4.9.3)\n",
      "Requirement already satisfied: composable<0.3.0,>=0.2.0 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (0.2.5)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (18.6.0)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.9.3->composablesoup) (1.9.5)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable<0.3.0,>=0.2.0->composablesoup) (0.11.1)\n",
      "Requirement already up-to-date: composable in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (18.6.0)\n",
      "Requirement already satisfied, skipping upgrade: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (0.11.1)\n",
      "Requirement already up-to-date: composablesoup in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (18.6.0)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4<5.0.0,>=4.9.3 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (4.9.3)\n",
      "Requirement already satisfied, skipping upgrade: composable<0.3.0,>=0.2.0 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: soupsieve>1.2; python_version >= \"3.0\" in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.9.3->composablesoup) (1.9.5)\n",
      "Requirement already satisfied, skipping upgrade: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable<0.3.0,>=0.2.0->composablesoup) (0.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install composable\n",
    "!pip install composablesoup\n",
    "!pip install composable --upgrade\n",
    "!pip install composablesoup --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composablesoup import find, find_all, get_text, has_attr\n",
    "from composable.sequence import slice, head\n",
    "from composable.strict import map, filter\n",
    "from composable.string import replace,split\n",
    "from composable import from_toolz as tlz\n",
    "from composable import pipeable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "s = requests.Session()\n",
    "r = s.get('https://www.thecurrent.org/playlist/2014-01-01/01.html')\n",
    "the_current = BeautifulSoup(r.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull off the song start time\n",
    "\n",
    "1. Inspect the element\n",
    "    1. This one is tricky\n",
    "    2. Time tag does not have a tag, but\n",
    "    3. The surrounding div does have a class\n",
    "2. Identify the html tag and class\n",
    "3. Use `find_all` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Write a function that extracts the start time.\n",
    "6. Write a single pipe to extract the start time.\n",
    "7. Confirm you have the right number of times.\n",
    "8. Package your code in a function called `get_start_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n  1:59 \\n\\n',\n",
       " '\\n\\n  1:54 \\n\\n',\n",
       " '\\n\\n  1:51 \\n\\n',\n",
       " '\\n\\n  1:46 \\n\\n',\n",
       " '\\n\\n  1:44 \\n\\n',\n",
       " '\\n\\n  1:38 \\n\\n',\n",
       " '\\n\\n  1:34 \\n\\n',\n",
       " '\\n\\n  1:31 \\n\\n',\n",
       " '\\n\\n  1:27 \\n\\n',\n",
       " '\\n\\n  1:23 \\n\\n',\n",
       " '\\n\\n  1:19 \\n\\n',\n",
       " '\\n\\n  1:13 \\n\\n',\n",
       " '\\n\\n  1:09 \\n\\n',\n",
       " '\\n\\n  1:05 \\n\\n',\n",
       " '\\n\\n  1:03 \\n\\n',\n",
       " '\\n\\n  1:01 \\n\\n']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(the_current\n",
    ">> find_all('div', attrs ={'class':'two columns songTime'})\n",
    ">>map(get_text)\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:59',\n",
       " '1:54',\n",
       " '1:51',\n",
       " '1:46',\n",
       " '1:44',\n",
       " '1:38',\n",
       " '1:34',\n",
       " '1:31',\n",
       " '1:27',\n",
       " '1:23',\n",
       " '1:19',\n",
       " '1:13',\n",
       " '1:09',\n",
       " '1:05',\n",
       " '1:03',\n",
       " '1:01']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_space = pipeable(lambda l: l.strip())\n",
    "(the_current\n",
    ">> find_all('div', attrs ={'class':'two columns songTime'})\n",
    ">>map(get_text)\n",
    ">>map(clean_space)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:59',\n",
       " '1:54',\n",
       " '1:51',\n",
       " '1:46',\n",
       " '1:44',\n",
       " '1:38',\n",
       " '1:34',\n",
       " '1:31',\n",
       " '1:27',\n",
       " '1:23',\n",
       " '1:19',\n",
       " '1:13',\n",
       " '1:09',\n",
       " '1:05',\n",
       " '1:03',\n",
       " '1:01']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_start_time = pipeable(lambda soup:\n",
    "the_current\n",
    ">> find_all('div', attrs ={'class':'two columns songTime'})\n",
    ">>map(get_text)\n",
    ">>map(clean_space)\n",
    "\n",
    ")\n",
    "the_current >> get_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull address of the album art image address\n",
    "\n",
    "Follow a similar process to pull off the web address of the album cover image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://albumart.publicradio.org/mb/e2/e2749c25-c2b6-493e-a2bb-10898152bd2d_5158.jpg',\n",
       " 'https://albumart.publicradio.org/mb/5e/5e5c8b95-d04c-432f-8cd2-c1c8d99e6e5a_3556.jpg',\n",
       " 'https://albumart.publicradio.org/mb/48/48445b64-d965-369a-af3c-8193de389fd8_3ff4.jpg',\n",
       " 'https://albumart.publicradio.org/mb/e9/e999c049-c65b-4c5e-ad12-5596998679c7_92f9.jpg',\n",
       " 'https://albumart.publicradio.org/mb/d6/d62320e2-20c4-4589-aa76-2f8ac28447dd_e03b.jpg',\n",
       " 'https://albumart.publicradio.org/mb/02/028b8602-3bde-495a-a7da-15594fc4f786_351a.jpg',\n",
       " 'https://albumart.publicradio.org/mb/c9/c92f73ee-527f-42ed-a556-fd615941e214_78f0.jpg',\n",
       " 'https://albumart.publicradio.org/mb/24/24084807-5d23-423e-b1f3-5e9fd874e240_6ccd.jpg',\n",
       " 'https://albumart.publicradio.org/mb/c2/c20be759-d767-4a7c-96c5-7a870ebc3a30_7f7d.jpg',\n",
       " 'https://albumart.publicradio.org/mb/37/37f48931-e5e6-488f-a531-ad2db311158d_7446.jpg',\n",
       " 'https://albumart.publicradio.org/mb/1a/1aa41b19-5a72-341b-bd91-4cf61d1dab6b_8e05.jpg']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(the_current\n",
    ">> find_all('img', attrs ={'class':\"album-art\"})\n",
    ">> filter(has_attr('data-src'))\n",
    ">> map(tlz.get('data-src'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://albumart.publicradio.org/mb/e2/e2749c25-c2b6-493e-a2bb-10898152bd2d_5158.jpg',\n",
       " 'https://albumart.publicradio.org/mb/5e/5e5c8b95-d04c-432f-8cd2-c1c8d99e6e5a_3556.jpg',\n",
       " 'https://albumart.publicradio.org/mb/48/48445b64-d965-369a-af3c-8193de389fd8_3ff4.jpg',\n",
       " 'https://albumart.publicradio.org/mb/e9/e999c049-c65b-4c5e-ad12-5596998679c7_92f9.jpg',\n",
       " 'https://albumart.publicradio.org/mb/d6/d62320e2-20c4-4589-aa76-2f8ac28447dd_e03b.jpg',\n",
       " 'https://albumart.publicradio.org/mb/02/028b8602-3bde-495a-a7da-15594fc4f786_351a.jpg',\n",
       " 'https://albumart.publicradio.org/mb/c9/c92f73ee-527f-42ed-a556-fd615941e214_78f0.jpg',\n",
       " 'https://albumart.publicradio.org/mb/24/24084807-5d23-423e-b1f3-5e9fd874e240_6ccd.jpg',\n",
       " 'https://albumart.publicradio.org/mb/c2/c20be759-d767-4a7c-96c5-7a870ebc3a30_7f7d.jpg',\n",
       " 'https://albumart.publicradio.org/mb/37/37f48931-e5e6-488f-a531-ad2db311158d_7446.jpg',\n",
       " 'https://albumart.publicradio.org/mb/1a/1aa41b19-5a72-341b-bd91-4cf61d1dab6b_8e05.jpg']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_img_address = pipeable(lambda soup: soup\n",
    "    >> find_all('img', attrs ={'class':\"album-art\"})\n",
    "    >> filter(has_attr('data-src'))\n",
    "    >> map(tlz.get('data-src'))\n",
    ")\n",
    "the_current >> get_img_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "* Make a function for each of the previous steps\n",
    "* Make an overall function\n",
    "    * input is a soup\n",
    "    * output is a list of lists\n",
    "\n",
    "**Hint:** You should use `zip` to put all the information together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Holy Roller',\n",
       "  'Thao and The Get Down Stay Down',\n",
       "  '1:59',\n",
       "  'https://albumart.publicradio.org/mb/e2/e2749c25-c2b6-493e-a2bb-10898152bd2d_5158.jpg'),\n",
       " ('Kingdom of Rust',\n",
       "  'Doves',\n",
       "  '1:54',\n",
       "  'https://albumart.publicradio.org/mb/5e/5e5c8b95-d04c-432f-8cd2-c1c8d99e6e5a_3556.jpg'),\n",
       " ('Black Dog',\n",
       "  'Frankie Lee',\n",
       "  '1:51',\n",
       "  'https://albumart.publicradio.org/mb/48/48445b64-d965-369a-af3c-8193de389fd8_3ff4.jpg'),\n",
       " ('Turn It Around',\n",
       "  'Lucius',\n",
       "  '1:46',\n",
       "  'https://albumart.publicradio.org/mb/e9/e999c049-c65b-4c5e-ad12-5596998679c7_92f9.jpg'),\n",
       " ('Flavor of the Month',\n",
       "  'The Posies',\n",
       "  '1:44',\n",
       "  'https://albumart.publicradio.org/mb/d6/d62320e2-20c4-4589-aa76-2f8ac28447dd_e03b.jpg'),\n",
       " ('Potential Wife',\n",
       "  'Strange Names',\n",
       "  '1:38',\n",
       "  'https://albumart.publicradio.org/mb/02/028b8602-3bde-495a-a7da-15594fc4f786_351a.jpg'),\n",
       " ('24 Hours',\n",
       "  'Sky Ferreira',\n",
       "  '1:34',\n",
       "  'https://albumart.publicradio.org/mb/c9/c92f73ee-527f-42ed-a556-fd615941e214_78f0.jpg'),\n",
       " (\"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       "  'Billie Joe and Norah',\n",
       "  '1:31',\n",
       "  'https://albumart.publicradio.org/mb/24/24084807-5d23-423e-b1f3-5e9fd874e240_6ccd.jpg'),\n",
       " ('Marigold',\n",
       "  'J. Roddy Walston and The Business',\n",
       "  '1:27',\n",
       "  'https://albumart.publicradio.org/mb/c2/c20be759-d767-4a7c-96c5-7a870ebc3a30_7f7d.jpg'),\n",
       " ('High Road',\n",
       "  'Cults',\n",
       "  '1:23',\n",
       "  'https://albumart.publicradio.org/mb/37/37f48931-e5e6-488f-a531-ad2db311158d_7446.jpg'),\n",
       " ('The Vampyre Of Time and Memory',\n",
       "  'Queens of the Stone Age',\n",
       "  '1:19',\n",
       "  'https://albumart.publicradio.org/mb/1a/1aa41b19-5a72-341b-bd91-4cf61d1dab6b_8e05.jpg'))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = lambda soup: zip(soup>> get_title, soup >> get_artist, soup >>get_start_time, soup >> get_img_address)\n",
    "tuple(output(the_current))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip = pipeable(lambda s: s.strip() )\n",
    "(the_current\n",
    " >> find(\"span\", attrs = {'class' : 'hour-header'})\n",
    " >> get_text\n",
    " >> strip\n",
    " >> split(\" \")\n",
    " >> tlz.get(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_period = pipeable(lambda soup: soup\n",
    "                        >> find(\"span\", attrs = {'class' : 'hour-header'})\n",
    "                         >> get_text\n",
    "                         >> strip\n",
    "                         >> split(\" \")\n",
    "                         >> tlz.get(1)\n",
    "                                        )\n",
    "the_current >> get_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thao and The Get Down Stay Down',\n",
       " 'Doves',\n",
       " 'Frankie Lee',\n",
       " 'Lucius',\n",
       " 'The Posies',\n",
       " 'Strange Names',\n",
       " 'Sky Ferreira',\n",
       " 'Billie Joe and Norah',\n",
       " 'J. Roddy Walston and The Business',\n",
       " 'Cults',\n",
       " 'Queens of the Stone Age',\n",
       " 'The Decemberists',\n",
       " 'The Avett Brothers',\n",
       " 'David Bowie',\n",
       " 'Jack White',\n",
       " 'Pixies']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_artist = pipeable(lambda soup: soup\n",
    " >> find_all('h5', attrs ={'class':'artist'})\n",
    " >> map(get_text)\n",
    "\n",
    ")\n",
    "the_current>>get_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Holy Roller',\n",
       " 'Kingdom of Rust',\n",
       " 'Black Dog',\n",
       " 'Turn It Around',\n",
       " 'Flavor of the Month',\n",
       " 'Potential Wife',\n",
       " '24 Hours',\n",
       " \"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       " 'Marigold',\n",
       " 'High Road',\n",
       " 'The Vampyre Of Time and Memory',\n",
       " 'Valerie Plame',\n",
       " 'Morning Song',\n",
       " '(You Will) Set The World On Fire',\n",
       " 'Sixteen Saltines',\n",
       " 'Wave of Mutilation']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_title = pipeable(lambda soup: soup\n",
    " >> find_all('h5', attrs ={'class':'title'})\n",
    " >> map(get_text)\n",
    ")\n",
    "the_current>>get_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DJ: Jade'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_DJ = pipeable(lambda soup: soup\n",
    " >> find('h5', attrs ={'class':'currentDj'})\n",
    " >> get_text\n",
    "\n",
    ")\n",
    "the_current>>get_DJ"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
