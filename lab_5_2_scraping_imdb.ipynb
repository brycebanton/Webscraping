{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5.2 -- Scraping IMBD\n",
    "\n",
    "Our goal is to scrap [IMDB](imdb.com) user reviews for *Borat Subsequent Moviefilm*.  Unfortunately, the page for user reviews only shows a limited number of reviews and you can't access additional pages through a link.  `selenium` to the rescue! In this lab, we will combine our two approaches to web scraping by\n",
    "\n",
    "1. Using `selenium` to load the page and click the *Load More* until we have all the reviews.\n",
    "2. Creating a `BeautifulSoup` instance for the complete page and parsing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 -- Load the reviews.\n",
    "\n",
    "Explore IMBD to find the web link for the user reviews for *Borat Subsequent Moviefilm* and load this page in Python with `selenium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composablesoup import find, find_all, get_text, has_attr\n",
    "from composable.sequence import slice, head\n",
    "from composable.strict import map, filter\n",
    "from composable.string import replace,split\n",
    "from composable import from_toolz as tlz\n",
    "from composable import pipeable\n",
    "from composablesoup.soup import find_parent, parents, children, find_previous_sibling, find_previous_siblings, find_next_sibling, find_next_siblings, find_previous_sibling\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "\u001b[K     |████████████████████████████████| 904 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from selenium) (1.25.8)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "DRIVER_PATH = '/mnt/c/Users/vn6415dw/Desktop/chromedriver.exe'\n",
    "driver = webdriver.Chrome(executable_path= DRIVER_PATH)\n",
    "driver.get('https://www.imdb.com/title/tt13143964/reviews?ref_=tt_ov_rt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 -- Figure out how to click the *Load More* button.\n",
    "\n",
    "To load all of the user reviews, we need to click the *Load More* button multiple times.  First, find the corresponding WebElement and verify that clicking this button loads another page of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click Number 1\n"
     ]
    }
   ],
   "source": [
    "keep_running = True\n",
    "i = 0\n",
    "while keep_running and i < 1000:\n",
    "    try:\n",
    "        i = i + 1\n",
    "        load_more.click()\n",
    "        print('Click Number {0}'.format(i))\n",
    "    except:\n",
    "        keep_running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"b58a5d56cb66813673f07ecd5f61d16c\", element=\"2850f5c9-1cb2-4a50-9703-60633007f991\")>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_more = driver.find_element_by_id('load-more-trigger')\n",
    "load_more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_more.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 -- Click *Load More* until you have all the results.\n",
    "\n",
    "Now you need to write code that will keep clicking the *Load More* button when you find it.  **Hint:** We can think of this as an example of an *unfold* process, meaning you should use a `while` loop combined with a [try-and-except statement](https://pythonbasics.org/try-except/) to keep trying to click the button.  To make sure you don't get an infinite loop, use a variable to identify and hold the stopping condition/state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver,15)\n",
    "load_more = wait.until(EC.element_to_be_clickable((By.ID, 'load-more-trigger')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_running = True\n",
    "i = 0\n",
    "while keep_running and i < 1000:\n",
    "    try:\n",
    "        i = i + 1\n",
    "        load_more.click()\n",
    "        print('Click Number {0}'.format(i))\n",
    "        load_more = wait.until(EC.element_to_be_clickable((By.ID, 'load-more-trigger')))\n",
    "    except:\n",
    "        keep_running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.page.source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 -- Load the results in a `BeautifulSoup` object.\n",
    "\n",
    "Since `bs4` has better tools for parsing html, we will now switch to using this module to parse the results.  Recall that you can access the content of the current content from the `selenium` driver using `driver.page_source`.  You can use this attribute to make a `soup` object for the page using \n",
    "\n",
    "> soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_soup = BeautifulSoup(driver.page.source, 'html.parser')\n",
    "review_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 -- Extract the information\n",
    "\n",
    "Now extract the following data to a csv file.\n",
    "\n",
    "1. Title\n",
    "2. Score\n",
    "3. User\n",
    "4. Date\n",
    "5. Text (replace commas with semi-colons!)\n",
    "6. Two columns for X and Y, where `\"X out of Y found this helpful\"`\n",
    "7. Permanent link the the review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
