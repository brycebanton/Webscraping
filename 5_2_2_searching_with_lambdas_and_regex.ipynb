{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution\n",
    "\n",
    "These slides were adapted from [the companion notebooks](https://github.com/REMitchell/python-scraping) for [Web Scraping in Python](http://shop.oreilly.com/product/0636920034391.do), which are open sourced and provided for free.  If you are interested in a more detailed presentation of web scraping in Python, this book is a great source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: composable in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (0.11.1)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (18.6.0)\n",
      "Requirement already satisfied: composablesoup in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.1.1)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (18.6.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.3 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (4.9.3)\n",
      "Requirement already satisfied: composable<0.3.0,>=0.2.0 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (0.2.4)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.9.3->composablesoup) (1.9.5)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable<0.3.0,>=0.2.0->composablesoup) (0.11.1)\n"
     ]
    }
   ],
   "source": [
    "# Install if needed\n",
    "!pip install composable\n",
    "!pip install composablesoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting composable\n",
      "  Downloading composable-0.2.5-py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied, skipping upgrade: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (0.11.1)\n",
      "Requirement already satisfied, skipping upgrade: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (18.6.0)\n",
      "Installing collected packages: composable\n",
      "  Attempting uninstall: composable\n",
      "    Found existing installation: composable 0.2.4\n",
      "    Uninstalling composable-0.2.4:\n",
      "      Successfully uninstalled composable-0.2.4\n",
      "Successfully installed composable-0.2.5\n",
      "Collecting composablesoup\n",
      "  Downloading composablesoup-0.2.4-py3-none-any.whl (4.0 kB)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4<5.0.0,>=4.9.3 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (4.9.3)\n",
      "Requirement already satisfied, skipping upgrade: python-forge<19.0,>=18.6 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (18.6.0)\n",
      "Requirement already satisfied, skipping upgrade: composable<0.3.0,>=0.2.0 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: soupsieve>1.2; python_version >= \"3.0\" in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.9.3->composablesoup) (1.9.5)\n",
      "Requirement already satisfied, skipping upgrade: toolz<0.12.0,>=0.11.1 in /home/vn6415dw/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable<0.3.0,>=0.2.0->composablesoup) (0.11.1)\n",
      "Installing collected packages: composablesoup\n",
      "  Attempting uninstall: composablesoup\n",
      "    Found existing installation: composablesoup 0.1.1\n",
      "    Uninstalling composablesoup-0.1.1:\n",
      "      Successfully uninstalled composablesoup-0.1.1\n",
      "Successfully installed composablesoup-0.2.4\n"
     ]
    }
   ],
   "source": [
    "# Check for upgrade is already installed\n",
    "!pip install composable --upgrade\n",
    "!pip install composablesoup --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composable import pipeable\n",
    "from composable.strict import map, filter\n",
    "from composablesoup import find, find_all, get_text, has_attr\n",
    "from composablesoup.soup import find_parent, parents, children, find_previous_sibling, find_previous_siblings, find_next_sibling, find_next_siblings, find_previous_sibling\n",
    "from composable.sequence import to_list, head\n",
    "from composable.string import strip\n",
    "from composable import from_toolz as tlz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching with `lambda` functions\n",
    "\n",
    "We can use a lambda function \n",
    "* to perform more complicated searches.\n",
    "* **Syntax:** `bs.find_all(lambda tag: bool_expr)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Let's find all tags with exactly 2 attributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "s = requests.Session()\n",
    "r = s.get('http://www.pythonscraping.com/pages/page3.html')\n",
    "items_for_sale = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img src=\"../img/gifts/logo.jpg\" style=\"float:left;\"/>,\n",
       " <tr class=\"gift\" id=\"gift1\"><td>\n",
       " Vegetable Basket\n",
       " </td><td>\n",
       " This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
       " <span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
       " </td><td>\n",
       " $15.00\n",
       " </td><td>\n",
       " <img src=\"../img/gifts/img1.jpg\"/>\n",
       " </td></tr>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(items_for_sale\n",
    " >> find_all(lambda tag: len(tag.attrs) == 2)\n",
    " >> head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Let's find all tags containing a specific piece of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"excitingNote\">Or maybe he's only resting?</span>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(items_for_sale\n",
    " >> find_all(lambda tag: tag.get_text() == 'Or maybe he\\'s only resting?')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Or maybe he's only resting?\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(items_for_sale\n",
    " >> find_all('', text='Or maybe he\\'s only resting?')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching with regular expressions\n",
    "\n",
    "The ultimate tool for performing complex text searches is a Regular Expression, which will be our next topic of discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../img/gifts/img1.jpg',\n",
       " '../img/gifts/img2.jpg',\n",
       " '../img/gifts/img3.jpg',\n",
       " '../img/gifts/img4.jpg',\n",
       " '../img/gifts/img6.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "gift_img = re.compile('\\.\\.\\/img\\/gifts/img.*\\.jpg')\n",
    "\n",
    "(items_for_sale\n",
    " >> find_all('img', attrs={'src': gift_img})\n",
    " >> map(tlz.get('src')) # why is ok to skip the filter?\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
